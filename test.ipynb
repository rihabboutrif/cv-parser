{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "installing dependencies"
      ],
      "metadata": {
        "id": "prhaG5Pp1EKd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKkMumVV0551"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download fr_core_news_md\n",
        "!pip install spacy spacy-layout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test the model on one single pdf"
      ],
      "metadata": {
        "id": "UWMMBkVY1KKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy_layout import spaCyLayout\n",
        "\n",
        "# ===========================\n",
        "# 1Ô∏è‚É£ Load models\n",
        "# ===========================\n",
        "# Layout model (for PDF parsing)\n",
        "nlp_layout = spacy.load(\"fr_core_news_md\")\n",
        "layout = spaCyLayout(nlp_layout)\n",
        "\n",
        "# Text classification model\n",
        "model_path = \"./model\"\n",
        "nlp_classifier = spacy.load(model_path)\n",
        "\n",
        "# ===========================\n",
        "# 2Ô∏è‚É£ Process PDF\n",
        "# ===========================\n",
        "pdf_path = \"t.pdf\"\n",
        "doc = layout(pdf_path)\n",
        "\n",
        "# ===========================\n",
        "# 3Ô∏è‚É£ Extract items from layout spans\n",
        "# ===========================\n",
        "items = []\n",
        "for span in doc.spans.get(\"layout\", []):\n",
        "    label = span.label_.lower()\n",
        "    text = span.text.strip()\n",
        "    if text:\n",
        "        items.append({\"label\": label, \"text\": text})\n",
        "\n",
        "# ===========================\n",
        "# 4Ô∏è‚É£ Group headers + content\n",
        "# ===========================\n",
        "structured_doc = {}\n",
        "current_header_parts = []\n",
        "current_content = []\n",
        "\n",
        "for item in items:\n",
        "    label = item[\"label\"]\n",
        "    text = item[\"text\"]\n",
        "\n",
        "    if label in [\"section_header\", \"title\", \"heading\", \"section-header\", \"header\"]:\n",
        "        if current_content:\n",
        "            merged_header = \"\\n\".join(current_header_parts) if current_header_parts else \"Introduction\"\n",
        "            structured_doc[merged_header] = \"\\n\".join(current_content)\n",
        "            current_content = []\n",
        "            current_header_parts = [text]\n",
        "        else:\n",
        "            current_header_parts.append(text)\n",
        "\n",
        "    elif label in [\"paragraph\", \"body\", \"text\", \"list_item\", \"section\"]:\n",
        "        if not current_header_parts:\n",
        "            current_header_parts = [\"Introduction\"]\n",
        "        current_content.append(text)\n",
        "\n",
        "# Save the last block\n",
        "if current_header_parts and current_content:\n",
        "    merged_header = \"\\n\".join(current_header_parts)\n",
        "    structured_doc[merged_header] = \"\\n\".join(current_content)\n",
        "\n",
        "# ===========================\n",
        "# 5Ô∏è‚É£ Classify each block\n",
        "# ===========================\n",
        "results = []\n",
        "\n",
        "for header, content in structured_doc.items():\n",
        "    merged_text = header + \"\\n\" + content\n",
        "    doc_pred = nlp_classifier(merged_text)\n",
        "    predicted_category = max(doc_pred.cats, key=doc_pred.cats.get)\n",
        "\n",
        "    results.append({\n",
        "        \"merged_text\": merged_text,\n",
        "        \"predicted_category\": predicted_category\n",
        "    })\n",
        "\n",
        "# ===========================\n",
        "# 6Ô∏è‚É£ Print results\n",
        "# ===========================\n",
        "for r in results:\n",
        "    print(\"üìå Merged Text:\\n\", r[\"merged_text\"])\n",
        "    print(\"Predicted Category:\", r[\"predicted_category\"])\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "e1WYyoUN0-ZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}