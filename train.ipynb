{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install spacy"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zZank_vW9D-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr_core_news_md"
      ],
      "metadata": {
        "id": "ws_4kAIn4Jph",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting json files generated by mistral to spacy format  "
      ],
      "metadata": {
        "id": "8KZsVppf7olD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# === CONFIG ===\n",
        "input_folder = \"/content/drive/MyDrive/merged_jsons\"  # your merged JSONs\n",
        "output_folder = \"/content/drive/MyDrive/spacy_corpus_finale1\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load blank French model\n",
        "nlp = spacy.blank(\"fr\")\n",
        "\n",
        "# Label normalization and mapping\n",
        "def map_label(label):\n",
        "    label_lower = label.strip().lower()\n",
        "    label_map = {\n",
        "    # PHONE related\n",
        "    \"phone_number\": \"phone\",\n",
        "    \"phone\": \"phone\",\n",
        "    \"skype\": \"phone\",\n",
        "\n",
        "    # EXPERIENCE related\n",
        "    \"experiences\": \"experience\",\n",
        "    \"experience\": \"experience\",\n",
        "    \"freelance_work\": \"experience\",\n",
        "\n",
        "    # PROJECTS related\n",
        "    \"projects_esprit\": \"projects\",\n",
        "    \"academic_projects\": \"projects\",\n",
        "    \"projects\": \"projects\",\n",
        "\n",
        "    # TECHNICAL SKILLS related\n",
        "    \"technical_skills\": \"technical_skills\",\n",
        "    \"office_skills\": \"technical_skills\",\n",
        "    \"additional_skills\": \"technical_skills\",\n",
        "    \"modeling\": \"technical_skills\",\n",
        "    \"versioning\": \"technical_skills\",\n",
        "    \"database_administration\": \"technical_skills\",\n",
        "\n",
        "    # CERTIFICATIONS\n",
        "    \"certifications\": \"certifications\",\n",
        "    \"certificates\": \"certifications\",\n",
        "    \"certification\": \"certifications\",\n",
        "    \"technical_certifications\": \"certifications\",\n",
        "\n",
        "    # EDUCATION\n",
        "    \"education\": \"education\",\n",
        "    \"high_school\": \"education\",\n",
        "\n",
        "    # INTERNSHIPS\n",
        "    \"internships\": \"internships\",\n",
        "\n",
        "    # SOFT SKILLS\n",
        "    \"soft_skills\": \"soft_skills\",\n",
        "\n",
        "    # PERSONAL INFO\n",
        "    \"name\": \"name\",\n",
        "    \"email\": \"email\",\n",
        "    \"country\": \"country\",\n",
        "    \"city\": \"country\",\n",
        "    \"address\": \"country\",\n",
        "    \"location\": \"country\",\n",
        "\n",
        "    # LANGUAGES\n",
        "    \"languages\": \"languages\",\n",
        "    \"language\": \"languages\"\n",
        "   }\n",
        "\n",
        "    return label_map.get(label_lower, None)  # None = skip unwanted labels\n",
        "\n",
        "# Collect examples\n",
        "all_examples = []\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(os.path.join(input_folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            cv = json.load(f)\n",
        "\n",
        "        for key, value in cv.items():\n",
        "            if not value:\n",
        "                continue\n",
        "\n",
        "            new_label = map_label(key)\n",
        "            if new_label is None:\n",
        "                continue  # skip unwanted labels\n",
        "\n",
        "            # Merge lists/dicts into single string\n",
        "            if isinstance(value, list):\n",
        "                text_parts = []\n",
        "                for item in value:\n",
        "                    if isinstance(item, dict):\n",
        "                        text_parts.append(\", \".join(str(v) for v in item.values()))\n",
        "                    else:\n",
        "                        text_parts.append(str(item))\n",
        "                text = \" | \".join(text_parts)\n",
        "            elif isinstance(value, dict):\n",
        "                text = \", \".join(str(v) for v in value.values())\n",
        "            else:\n",
        "                text = str(value)\n",
        "\n",
        "            all_examples.append((text, new_label))\n",
        "\n",
        "# Shuffle and split train/dev\n",
        "random.shuffle(all_examples)\n",
        "split = int(0.8 * len(all_examples))\n",
        "train_data = all_examples[:split]\n",
        "dev_data = all_examples[split:]\n",
        "\n",
        "# Convert to DocBin\n",
        "def to_docbin(examples, out_path):\n",
        "    db = DocBin()\n",
        "    for text, label in examples:\n",
        "        doc = nlp.make_doc(text)\n",
        "        doc.cats = {label: 1.0}\n",
        "        db.add(doc)\n",
        "    db.to_disk(out_path)\n",
        "\n",
        "# Save\n",
        "to_docbin(train_data, os.path.join(output_folder, \"train.spacy\"))\n",
        "to_docbin(dev_data, os.path.join(output_folder, \"dev.spacy\"))\n",
        "\n",
        "print(\"‚úÖ Conversion done! Check folder:\", output_folder)\n",
        "print(f\"Total examples: {len(all_examples)}\")\n",
        "\n",
        "# Optional: show label counts\n",
        "counter = Counter([label for _, label in all_examples])\n",
        "print(\"Example counts per label:\")\n",
        "for k, v in counter.most_common():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRFz1pD58Esy",
        "outputId": "2526cf3e-0133-4cd1-a97e-7d4f38b9298a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Conversion done! Check folder: /content/drive/MyDrive/spacy_corpus_finale1\n",
            "Total examples: 3161\n",
            "Example counts per label:\n",
            "country: 426\n",
            "technical_skills: 416\n",
            "name: 411\n",
            "email: 408\n",
            "education: 391\n",
            "internships: 333\n",
            "phone: 319\n",
            "projects: 306\n",
            "soft_skills: 118\n",
            "languages: 15\n",
            "certifications: 11\n",
            "experience: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation of train data"
      ],
      "metadata": {
        "id": "9iklKX_K5yZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# CONFIG\n",
        "# ===============================\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/train.spacy\"\n",
        "DEV_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/dev.spacy\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/train_augmented.spacy\"\n",
        "\n",
        "# Small labels to oversample\n",
        "SMALL_LABELS = [\"experience\", \"internships\", \"projects\", \"languages\", \"soft_skills\", \"certifications\", \"profile\"]\n",
        "\n",
        "# ===============================\n",
        "# GENERATORS\n",
        "# ===============================\n",
        "def make_experience():\n",
        "    companies = [\"Capgemini\", \"Deloitte\", \"Sopra Steria\", \"BNP Paribas\", \"Vermeg\", \"Ooredoo\", \"Microsoft\", \"IBM\"]\n",
        "    roles = [\"D√©veloppeur Full Stack\", \"Data Scientist\", \"Consultant Big Data\", \"Ing√©nieur Cloud\", \"Analyste Cybers√©curit√©\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement et maintenance d‚Äôapplications\",\n",
        "        \"mise en place de pipelines de donn√©es\",\n",
        "        \"d√©ploiement de solutions cloud s√©curis√©es\",\n",
        "        \"optimisation de mod√®les d‚ÄôIA\",\n",
        "        \"gestion d‚Äô√©quipes agiles et reporting\",\n",
        "        \"analyse des besoins clients et r√©daction des sp√©cifications\",\n",
        "        \"conception d‚Äôarchitectures logicielles √©volutives\"\n",
        "    ]\n",
        "    years = [\"2020‚Äì2022\", \"2019‚Äì2021\", \"2021‚Äì2023\", \"2022‚Äì2024\"]\n",
        "    num_tasks = random.randint(2, 4)\n",
        "    responsibilities = \" ; \".join(random.sample(tasks, num_tasks))\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(years)}) ‚Äì Responsabilit√©s : {responsibilities}\"\n",
        "\n",
        "def make_internship():\n",
        "    companies = [\"Orange\", \"Eni\", \"STMicroelectronics\", \"Sagemcom\", \"SNCFT\", \"Tunisie T√©l√©com\"]\n",
        "    roles = [\"Stagiaire D√©veloppement Web\", \"Stagiaire Data Analyst\", \"Stagiaire DevOps\", \"Stagiaire S√©curit√© Informatique\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement d‚Äôun module interne\",\n",
        "        \"analyse de donn√©es clients\",\n",
        "        \"mise en place d‚Äôun pipeline CI/CD\",\n",
        "        \"r√©daction de documentation technique\",\n",
        "        \"tests et validation des fonctionnalit√©s\"\n",
        "    ]\n",
        "    periods = [\"Juin‚ÄìAo√ªt 2023\", \"Janvier‚ÄìJuin 2022\", \"F√©vrier‚ÄìAvril 2021\", \"Mars‚ÄìAo√ªt 2020\"]\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(periods)}) ‚Äì Missions : {random.choice(tasks)}\"\n",
        "\n",
        "def make_project():\n",
        "    projects = [\n",
        "        \"Projet universitaire : cr√©ation d‚Äôune application e-commerce en Django\",\n",
        "        \"Projet acad√©mique : d√©veloppement d‚Äôun chatbot NLP avec Python\",\n",
        "        \"Projet personnel : site web de gestion de t√¢ches avec React et Node.js\",\n",
        "        \"Projet de fin d‚Äô√©tudes : plateforme de recommandation musicale avec IA\",\n",
        "        \"Projet open-source : contribution √† une librairie Python de machine learning\",\n",
        "        \"Projet scientifique : analyse pr√©dictive des ventes avec Scikit-learn\"\n",
        "    ]\n",
        "    return random.choice(projects)\n",
        "\n",
        "def make_languages():\n",
        "    langs = [\n",
        "        \"Fran√ßais (courant), Anglais (avanc√©), Arabe (natif)\",\n",
        "        \"Anglais (TOEFL 95), Allemand (interm√©diaire)\",\n",
        "        \"Italien (d√©butant), Fran√ßais (C2), Anglais (C1)\",\n",
        "        \"Espagnol (B2), Arabe (langue maternelle)\"\n",
        "    ]\n",
        "    return random.choice(langs)\n",
        "\n",
        "def make_soft_skills():\n",
        "    skills = [\n",
        "        \"Esprit d‚Äô√©quipe et sens de la communication\",\n",
        "        \"Leadership et capacit√© de prise de d√©cision\",\n",
        "        \"R√©solution de probl√®mes complexes\",\n",
        "        \"Gestion du temps et organisation\",\n",
        "        \"Cr√©ativit√© et pens√©e critique\"\n",
        "    ]\n",
        "    return random.choice(skills)\n",
        "\n",
        "def make_certification():\n",
        "    certs = [\n",
        "        \"Certification AWS Solutions Architect ‚Äì Associate\",\n",
        "        \"Certification Cisco CCNA Routing & Switching\",\n",
        "        \"Certification PMP ‚Äì Project Management Professional\",\n",
        "        \"Certification Microsoft Azure Fundamentals\",\n",
        "        \"Certification Scrum Master (PSM I)\"\n",
        "    ]\n",
        "    return random.choice(certs)\n",
        "\n",
        "def make_profile():\n",
        "    profiles = [\n",
        "        \"Ing√©nieur logiciel passionn√© avec 3 ans d'exp√©rience en d√©veloppement full stack et en gestion de projets agiles.\",\n",
        "        \"Data Scientist sp√©cialis√© en machine learning et intelligence artificielle, avec un solide parcours acad√©mique et professionnel.\",\n",
        "        \"√âtudiant en informatique motiv√© par le d√©veloppement web et la cr√©ation d'applications innovantes.\",\n",
        "        \"Consultant Big Data orient√© r√©sultats, expert en analyse de donn√©es et optimisation des processus m√©tier.\",\n",
        "        \"D√©veloppeur polyvalent ma√Ætrisant Python, JavaScript et les technologies cloud, avec une forte capacit√© √† r√©soudre des probl√®mes complexes.\"\n",
        "    ]\n",
        "    return random.choice(profiles)\n",
        "\n",
        "GENERATORS = {\n",
        "    \"experience\": make_experience,\n",
        "    \"internships\": make_internship,\n",
        "    \"projects\": make_project,\n",
        "    \"languages\": make_languages,\n",
        "    \"soft_skills\": make_soft_skills,\n",
        "    \"certifications\": make_certification,\n",
        "    \"profile\": make_profile\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# MAIN SCRIPT\n",
        "# ===============================\n",
        "def main():\n",
        "    nlp = spacy.blank(\"fr\")\n",
        "\n",
        "    # Load train and dev\n",
        "    print(\"üîπ Loading datasets...\")\n",
        "    train_docs = list(DocBin().from_disk(TRAIN_FILE).get_docs(nlp.vocab))\n",
        "    dev_docs = list(DocBin().from_disk(DEV_FILE).get_docs(nlp.vocab))\n",
        "    print(f\"‚úÖ Loaded {len(train_docs)} train docs, {len(dev_docs)} dev docs\")\n",
        "\n",
        "    # Merge all docs for counting\n",
        "    all_docs = train_docs + dev_docs\n",
        "\n",
        "    # Count existing examples per class\n",
        "    counts = {}\n",
        "    for d in all_docs:\n",
        "        for k, v in d.cats.items():\n",
        "            if v == 1.0:\n",
        "                counts[k] = counts.get(k, 0) + 1\n",
        "    print(\"Current counts per class:\", counts)\n",
        "\n",
        "    max_count = max(counts.values())\n",
        "    print(\"Target count per small class:\", max_count)\n",
        "\n",
        "    # Generate new docs efficiently\n",
        "    new_docs = []\n",
        "    for label in SMALL_LABELS:\n",
        "        n_to_generate = max_count - counts.get(label, 0)\n",
        "        print(f\"Generating {n_to_generate} examples for {label}...\")\n",
        "        if n_to_generate <= 0:\n",
        "            continue\n",
        "        gen_func = GENERATORS[label]\n",
        "\n",
        "        # Bulk create docs\n",
        "        texts = [gen_func() for _ in range(n_to_generate)]\n",
        "        for text in texts:\n",
        "            doc = nlp.make_doc(text)\n",
        "            doc.cats = {k: 0.0 for k in counts.keys()}\n",
        "            doc.cats[label] = 1.0\n",
        "            new_docs.append(doc)\n",
        "\n",
        "    print(f\"‚úÖ Generated a total of {len(new_docs)} new docs\")\n",
        "\n",
        "    # Merge with train only (dev remains untouched)\n",
        "    final_docs = train_docs + new_docs\n",
        "    out_bin = DocBin(docs=final_docs)\n",
        "    out_bin.to_disk(OUTPUT_FILE)\n",
        "    print(f\"üéâ Augmented dataset saved! Total train examples: {len(final_docs)}\")\n",
        "\n",
        "    # Optional: final counts\n",
        "    final_counts = {}\n",
        "    for d in final_docs:\n",
        "        for k, v in d.cats.items():\n",
        "            if v == 1.0:\n",
        "                final_counts[k] = final_counts.get(k, 0) + 1\n",
        "    print(\"Final counts per class:\", final_counts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9hY6g_Vsbzx",
        "outputId": "a3aaf386-d5fc-4c1c-c200-47c0e2d5f4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Loading datasets...\n",
            "‚úÖ Loaded 2528 train docs, 633 dev docs\n",
            "Current counts per class: {'country': 426, 'phone': 319, 'soft_skills': 118, 'education': 391, 'projects': 306, 'email': 408, 'technical_skills': 416, 'name': 411, 'internships': 333, 'languages': 15, 'experience': 7, 'certifications': 11}\n",
            "Target count per small class: 426\n",
            "Generating 419 examples for experience...\n",
            "Generating 93 examples for internships...\n",
            "Generating 120 examples for projects...\n",
            "Generating 411 examples for languages...\n",
            "Generating 308 examples for soft_skills...\n",
            "Generating 415 examples for certifications...\n",
            "Generating 426 examples for profile...\n",
            "‚úÖ Generated a total of 2192 new docs\n",
            "üéâ Augmented dataset saved! Total train examples: 4720\n",
            "Final counts per class: {'country': 341, 'phone': 259, 'soft_skills': 399, 'education': 301, 'projects': 370, 'email': 322, 'technical_skills': 324, 'name': 341, 'internships': 362, 'languages': 424, 'experience': 426, 'certifications': 425, 'profile': 426}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation of dev data"
      ],
      "metadata": {
        "id": "SXbh1j2-5nPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# CONFIG\n",
        "# ===============================\n",
        "DEV_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/dev.spacy\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/deva.spacy\"\n",
        "\n",
        "# Small labels to oversample\n",
        "SMALL_LABELS = [\"experience\", \"internships\", \"projects\", \"languages\", \"soft_skills\", \"certifications\", \"profile\"]\n",
        "\n",
        "# ===============================\n",
        "# GENERATORS\n",
        "# ===============================\n",
        "def make_experience():\n",
        "    companies = [\"Capgemini\", \"Deloitte\", \"Sopra Steria\", \"BNP Paribas\", \"Vermeg\", \"Ooredoo\", \"Microsoft\", \"IBM\"]\n",
        "    roles = [\"D√©veloppeur Full Stack\", \"Data Scientist\", \"Consultant Big Data\", \"Ing√©nieur Cloud\", \"Analyste Cybers√©curit√©\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement et maintenance d‚Äôapplications\",\n",
        "        \"mise en place de pipelines de donn√©es\",\n",
        "        \"d√©ploiement de solutions cloud s√©curis√©es\",\n",
        "        \"optimisation de mod√®les d‚ÄôIA\",\n",
        "        \"gestion d‚Äô√©quipes agiles et reporting\",\n",
        "        \"analyse des besoins clients et r√©daction des sp√©cifications\",\n",
        "        \"conception d‚Äôarchitectures logicielles √©volutives\"\n",
        "    ]\n",
        "    years = [\"2020‚Äì2022\", \"2019‚Äì2021\", \"2021‚Äì2023\", \"2022‚Äì2024\"]\n",
        "    num_tasks = random.randint(2, 4)\n",
        "    responsibilities = \" ; \".join(random.sample(tasks, num_tasks))\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(years)}) ‚Äì Responsabilit√©s : {responsibilities}\"\n",
        "\n",
        "def make_internship():\n",
        "    companies = [\"Orange\", \"Eni\", \"STMicroelectronics\", \"Sagemcom\", \"SNCFT\", \"Tunisie T√©l√©com\"]\n",
        "    roles = [\"Stagiaire D√©veloppement Web\", \"Stagiaire Data Analyst\", \"Stagiaire DevOps\", \"Stagiaire S√©curit√© Informatique\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement d‚Äôun module interne\",\n",
        "        \"analyse de donn√©es clients\",\n",
        "        \"mise en place d‚Äôun pipeline CI/CD\",\n",
        "        \"r√©daction de documentation technique\",\n",
        "        \"tests et validation des fonctionnalit√©s\"\n",
        "    ]\n",
        "    periods = [\"Juin‚ÄìAo√ªt 2023\", \"Janvier‚ÄìJuin 2022\", \"F√©vrier‚ÄìAvril 2021\", \"Mars‚ÄìAo√ªt 2020\"]\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(periods)}) ‚Äì Missions : {random.choice(tasks)}\"\n",
        "\n",
        "def make_project():\n",
        "    projects = [\n",
        "        \"Projet universitaire : cr√©ation d‚Äôune application e-commerce en Django\",\n",
        "        \"Projet acad√©mique : d√©veloppement d‚Äôun chatbot NLP avec Python\",\n",
        "        \"Projet personnel : site web de gestion de t√¢ches avec React et Node.js\",\n",
        "        \"Projet de fin d‚Äô√©tudes : plateforme de recommandation musicale avec IA\",\n",
        "        \"Projet open-source : contribution √† une librairie Python de machine learning\",\n",
        "        \"Projet scientifique : analyse pr√©dictive des ventes avec Scikit-learn\"\n",
        "    ]\n",
        "    return random.choice(projects)\n",
        "\n",
        "def make_languages():\n",
        "    langs = [\n",
        "        \"Fran√ßais (courant), Anglais (avanc√©), Arabe (natif)\",\n",
        "        \"Anglais (TOEFL 95), Allemand (interm√©diaire)\",\n",
        "        \"Italien (d√©butant), Fran√ßais (C2), Anglais (C1)\",\n",
        "        \"Espagnol (B2), Arabe (langue maternelle)\"\n",
        "    ]\n",
        "    return random.choice(langs)\n",
        "\n",
        "def make_soft_skills():\n",
        "    skills = [\n",
        "        \"Esprit d‚Äô√©quipe et sens de la communication\",\n",
        "        \"Leadership et capacit√© de prise de d√©cision\",\n",
        "        \"R√©solution de probl√®mes complexes\",\n",
        "        \"Gestion du temps et organisation\",\n",
        "        \"Cr√©ativit√© et pens√©e critique\"\n",
        "    ]\n",
        "    return random.choice(skills)\n",
        "\n",
        "def make_certification():\n",
        "    certs = [\n",
        "        \"Certification AWS Solutions Architect ‚Äì Associate\",\n",
        "        \"Certification Cisco CCNA Routing & Switching\",\n",
        "        \"Certification PMP ‚Äì Project Management Professional\",\n",
        "        \"Certification Microsoft Azure Fundamentals\",\n",
        "        \"Certification Scrum Master (PSM I)\"\n",
        "    ]\n",
        "    return random.choice(certs)\n",
        "\n",
        "def make_profile():\n",
        "    profiles = [\n",
        "        \"Ing√©nieur logiciel passionn√© avec 3 ans d'exp√©rience en d√©veloppement full stack et en gestion de projets agiles.\",\n",
        "        \"Data Scientist sp√©cialis√© en machine learning et intelligence artificielle, avec un solide parcours acad√©mique et professionnel.\",\n",
        "        \"√âtudiant en informatique motiv√© par le d√©veloppement web et la cr√©ation d'applications innovantes.\",\n",
        "        \"Consultant Big Data orient√© r√©sultats, expert en analyse de donn√©es et optimisation des processus m√©tier.\",\n",
        "        \"D√©veloppeur polyvalent ma√Ætrisant Python, JavaScript et les technologies cloud, avec une forte capacit√© √† r√©soudre des probl√®mes complexes.\"\n",
        "    ]\n",
        "    return random.choice(profiles)\n",
        "\n",
        "GENERATORS = {\n",
        "    \"experience\": make_experience,\n",
        "    \"internships\": make_internship,\n",
        "    \"projects\": make_project,\n",
        "    \"languages\": make_languages,\n",
        "    \"soft_skills\": make_soft_skills,\n",
        "    \"certifications\": make_certification,\n",
        "    \"profile\": make_profile\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# MAIN SCRIPT\n",
        "# ===============================\n",
        "def main():\n",
        "    nlp = spacy.blank(\"fr\")\n",
        "    print(\"üîπ Loading dev dataset...\")\n",
        "    doc_bin = DocBin().from_disk(DEV_FILE)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "    print(f\"‚úÖ Loaded {len(docs)} dev examples\")\n",
        "\n",
        "    # Count current examples\n",
        "    counts = {}\n",
        "    for d in docs:\n",
        "        for label, v in d.cats.items():\n",
        "            if v == 1.0:\n",
        "                counts[label] = counts.get(label, 0) + 1\n",
        "\n",
        "    max_count = max(counts.values())\n",
        "    print(\"Largest class in dev:\", max_count)\n",
        "\n",
        "    # Generate synthetic examples\n",
        "    new_docs = []\n",
        "    for label in SMALL_LABELS:\n",
        "        n_to_generate = max_count - counts.get(label, 0)\n",
        "        gen = GENERATORS[label]\n",
        "        for _ in range(n_to_generate):\n",
        "            text = gen()\n",
        "            doc = nlp.make_doc(text)\n",
        "            doc.cats[label] = 1.0\n",
        "            # other labels = 0\n",
        "            for other_label in counts.keys():\n",
        "                if other_label != label:\n",
        "                    doc.cats[other_label] = 0.0\n",
        "            new_docs.append(doc)\n",
        "        print(f\"‚úÖ Generated {n_to_generate} new examples for {label}\")\n",
        "\n",
        "    # Merge and save\n",
        "    all_docs = docs + new_docs\n",
        "    DocBin(docs=all_docs).to_disk(OUTPUT_FILE)\n",
        "    print(f\"üéâ Dev augmentation complete! Total examples: {len(all_docs)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoYCksrCCI0l",
        "outputId": "2a0260ec-af80-400c-e19c-5de278839d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Loading dev dataset...\n",
            "‚úÖ Loaded 633 dev examples\n",
            "Largest class in dev: 92\n",
            "‚úÖ Generated 92 new examples for experience\n",
            "‚úÖ Generated 28 new examples for internships\n",
            "‚úÖ Generated 36 new examples for projects\n",
            "‚úÖ Generated 90 new examples for languages\n",
            "‚úÖ Generated 65 new examples for soft_skills\n",
            "‚úÖ Generated 91 new examples for certifications\n",
            "‚úÖ Generated 92 new examples for profile\n",
            "üéâ Dev augmentation complete! Total examples: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config config.cfg --lang fr --pipeline textcat --optimize accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6IMSU8HpI2o",
        "outputId": "159a3a84-0bbf-4bcb-9ac1-5289d5c4b7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m‚ö† To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Generated config template specific for your use case\u001b[0m\n",
            "- Language: fr\n",
            "- Pipeline: textcat\n",
            "- Optimize for: accuracy\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m‚úî Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m‚úî Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainnig process"
      ],
      "metadata": {
        "id": "RfZfwVPy5auH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg \\\n",
        "    --paths.train /content/drive/MyDrive/spacy_corpus_finale1/train_augmented.spacy \\\n",
        "    --paths.dev /content/drive/MyDrive/spacy_corpus_finale1/deva.spacy \\\n",
        "    --output  /content/drive/MyDrive/spacy_augmented_model \\\n",
        "    --gpu-id -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86LuYA01pO7e",
        "outputId": "e27b6d06-6a02-4f19-c3b2-3153546b650a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4m‚Ñπ Saving to output directory:\n",
            "/content/drive/MyDrive/spacy_augmented_model\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m‚úî Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Pipeline: ['tok2vec', 'textcat']\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
            "---  ------  ------------  ------------  ----------  ------\n",
            "  0       0          0.00          0.07       15.78    0.16\n",
            "  0     200         88.41          6.37       85.21    0.85\n",
            "  0     400        271.72          4.47       89.37    0.89\n",
            "  0     600       1044.02          3.69       83.42    0.83\n",
            "  1     800       2517.88          3.35       92.12    0.92\n",
            "  1    1000       5670.21          2.18       90.84    0.91\n",
            "  1    1200       6218.41          2.14       89.74    0.90\n",
            "  2    1400      18515.68          2.25       94.35    0.94\n",
            "  3    1600      36444.35          1.98       95.40    0.95\n",
            "  4    1800      58762.74          1.40       95.01    0.95\n",
            "  5    2000      63853.00          1.26       95.66    0.96\n",
            "  7    2200     102696.22          1.07       95.54    0.96\n",
            "  8    2400     119648.15          1.27       95.78    0.96\n",
            " 10    2600     140119.80          1.02       95.75    0.96\n",
            " 12    2800     171921.82          0.91       96.11    0.96\n",
            " 14    3000     196025.97          0.85       96.21    0.96\n",
            " 16    3200     222142.53          0.95       96.29    0.96\n",
            " 18    3400     385311.62          1.01       95.34    0.95\n",
            " 20    3600     289501.94          0.72       95.78    0.96\n",
            " 21    3800     569318.34          0.87       95.91    0.96\n",
            " 23    4000     435573.85          0.90       96.67    0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of first model"
      ],
      "metadata": {
        "id": "tvoIKj9m5VVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/spacy_augmented_model/model-best /content/drive/MyDrive/spacy_corpus_finale1/deva.spacy --gpu-id -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcrwYaFhSmTG",
        "outputId": "2a147dc4-b6f8-485e-ddc8-51f0caf93b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK                 100.00\n",
            "TEXTCAT (macro F)   96.67 \n",
            "SPEED               1901  \n",
            "\n",
            "\u001b[1m\n",
            "=========================== Textcat F (per label) ===========================\u001b[0m\n",
            "\n",
            "                        P        R        F\n",
            "country             98.80    96.47    97.62\n",
            "phone               98.28    95.00    96.61\n",
            "soft_skills         97.75    94.57    96.13\n",
            "education          100.00    97.78    98.88\n",
            "projects            92.05    88.04    90.00\n",
            "email              100.00    98.84    99.42\n",
            "technical_skills    93.68    96.74    95.19\n",
            "name                87.34    98.57    92.62\n",
            "internships         89.47    93.41    91.40\n",
            "languages          100.00    98.91    99.45\n",
            "experience         100.00   100.00   100.00\n",
            "certifications     100.00    98.91    99.45\n",
            "profile            100.00   100.00   100.00\n",
            "\n",
            "\u001b[1m\n",
            "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
            "\n",
            "                   ROC AUC\n",
            "country               1.00\n",
            "phone                 1.00\n",
            "soft_skills           0.99\n",
            "education             0.99\n",
            "projects              0.99\n",
            "email                 1.00\n",
            "technical_skills      1.00\n",
            "name                  1.00\n",
            "internships           0.99\n",
            "languages             1.00\n",
            "experience            1.00\n",
            "certifications        1.00\n",
            "profile               1.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation of dev data"
      ],
      "metadata": {
        "id": "VzeOm5sh5Q5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# CONFIG\n",
        "# ===============================\n",
        "DEV_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/deva.spacy\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/dev_augmented.spacy\"\n",
        "\n",
        "# Labels to oversample\n",
        "SMALL_LABELS = [\"experience\", \"internships\", \"projects\", \"languages\", \"soft_skills\", \"certifications\", \"profile\"]\n",
        "\n",
        "# ===============================\n",
        "# SECTION GENERATORS\n",
        "# ===============================\n",
        "\n",
        "def make_experience():\n",
        "    companies = [\"Capgemini\", \"Deloitte\", \"Sopra Steria\", \"BNP Paribas\", \"Vermeg\", \"Ooredoo\", \"Microsoft\", \"IBM\"]\n",
        "    roles = [\"D√©veloppeur Full Stack\", \"Data Scientist\", \"Consultant Big Data\", \"Ing√©nieur Cloud\", \"Analyste Cybers√©curit√©\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement et maintenance d‚Äôapplications\",\n",
        "        \"mise en place de pipelines de donn√©es\",\n",
        "        \"d√©ploiement de solutions cloud s√©curis√©es\",\n",
        "        \"optimisation de mod√®les d‚ÄôIA\",\n",
        "        \"gestion d‚Äô√©quipes agiles et reporting\",\n",
        "        \"analyse des besoins clients et r√©daction des sp√©cifications\",\n",
        "        \"conception d‚Äôarchitectures logicielles √©volutives\"\n",
        "    ]\n",
        "    years = [\"2020‚Äì2022\", \"2019‚Äì2021\", \"2021‚Äì2023\", \"2022‚Äì2024\"]\n",
        "    num_tasks = random.randint(2, 4)\n",
        "    responsibilities = \" ; \".join(random.sample(tasks, num_tasks))\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(years)}) ‚Äì Responsabilit√©s : {responsibilities}\"\n",
        "\n",
        "def make_experience_paragraph():\n",
        "    n = random.randint(2, 4)\n",
        "    connectors = [\n",
        "        \"Durant ces exp√©riences professionnelles, j'ai travaill√© sur plusieurs projets significatifs :\",\n",
        "        \"Ces missions m'ont permis de d√©velopper des comp√©tences cl√©s dans le domaine :\",\n",
        "        \"Au cours de ces exp√©riences, j'ai acquis de solides connaissances en :\"\n",
        "    ]\n",
        "    base_text = \" \".join(make_experience() for _ in range(n))\n",
        "    return f\"{random.choice(connectors)} {base_text}\"\n",
        "\n",
        "def make_internship_paragraph():\n",
        "    companies = [\"Orange\", \"Eni\", \"STMicroelectronics\", \"Sagemcom\", \"SNCFT\", \"Tunisie T√©l√©com\"]\n",
        "    roles = [\"Stagiaire D√©veloppement Web\", \"Stagiaire Data Analyst\", \"Stagiaire DevOps\", \"Stagiaire S√©curit√© Informatique\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement d‚Äôun module interne\",\n",
        "        \"analyse de donn√©es clients\",\n",
        "        \"mise en place d‚Äôun pipeline CI/CD\",\n",
        "        \"r√©daction de documentation technique\",\n",
        "        \"tests et validation des fonctionnalit√©s\",\n",
        "        \"participation √† des r√©unions de planification et d'√©valuation\"\n",
        "    ]\n",
        "    periods = [\"Juin‚ÄìAo√ªt 2023\", \"Janvier‚ÄìJuin 2022\", \"F√©vrier‚ÄìAvril 2021\", \"Mars‚ÄìAo√ªt 2020\"]\n",
        "\n",
        "    n = random.randint(3, 5)\n",
        "    sentences = []\n",
        "    for _ in range(n):\n",
        "        sentences.append(f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(periods)}), o√π j'ai effectu√© {random.choice(tasks)}.\")\n",
        "    connector = \"Au cours de mes stages, j'ai r√©alis√© plusieurs missions importantes :\"\n",
        "    return f\"{connector} {' '.join(sentences)}\"\n",
        "\n",
        "def make_project_paragraph():\n",
        "    projects = [\n",
        "        \"un projet universitaire de cr√©ation d‚Äôune application e-commerce en Django\",\n",
        "        \"un projet acad√©mique de d√©veloppement d‚Äôun chatbot NLP avec Python\",\n",
        "        \"un projet personnel de site web de gestion de t√¢ches avec React et Node.js\",\n",
        "        \"un projet de fin d‚Äô√©tudes : plateforme de recommandation musicale avec IA\",\n",
        "        \"une contribution open-source √† une librairie Python de machine learning\",\n",
        "        \"un projet scientifique d‚Äôanalyse pr√©dictive des ventes avec Scikit-learn\"\n",
        "    ]\n",
        "    n = random.randint(3, 5)\n",
        "    sentences = [f\"J'ai men√© {random.choice(projects)}.\" for _ in range(n)]\n",
        "    connector = \"Parmi les projets que j'ai r√©alis√©s, on peut citer :\"\n",
        "    return f\"{connector} {' '.join(sentences)}\"\n",
        "\n",
        "def make_languages():\n",
        "    langs = [\n",
        "        \"Fran√ßais (courant), Anglais (avanc√©), Arabe (natif)\",\n",
        "        \"Anglais (TOEFL 95), Allemand (interm√©diaire)\",\n",
        "        \"Italien (d√©butant), Fran√ßais (C2), Anglais (C1)\",\n",
        "        \"Espagnol (B2), Arabe (langue maternelle)\"\n",
        "    ]\n",
        "    return random.choice(langs)\n",
        "\n",
        "def make_soft_skills():\n",
        "    skills = [\n",
        "        \"Esprit d‚Äô√©quipe et sens de la communication\",\n",
        "        \"Leadership et capacit√© de prise de d√©cision\",\n",
        "        \"R√©solution de probl√®mes complexes\",\n",
        "        \"Gestion du temps et organisation\",\n",
        "        \"Cr√©ativit√© et pens√©e critique\"\n",
        "    ]\n",
        "    return random.choice(skills)\n",
        "\n",
        "def make_certification():\n",
        "    certs = [\n",
        "        \"Certification AWS Solutions Architect ‚Äì Associate\",\n",
        "        \"Certification Cisco CCNA Routing & Switching\",\n",
        "        \"Certification PMP ‚Äì Project Management Professional\",\n",
        "        \"Certification Microsoft Azure Fundamentals\",\n",
        "        \"Certification Scrum Master (PSM I)\"\n",
        "    ]\n",
        "    return random.choice(certs)\n",
        "\n",
        "def make_profile():\n",
        "    profiles = [\n",
        "        \"Ing√©nieur logiciel passionn√© avec 3 ans d'exp√©rience en d√©veloppement full stack et en gestion de projets agiles.\",\n",
        "        \"Data Scientist sp√©cialis√© en machine learning et intelligence artificielle, avec un solide parcours acad√©mique et professionnel.\",\n",
        "        \"√âtudiant en informatique motiv√© par le d√©veloppement web et la cr√©ation d'applications innovantes.\",\n",
        "        \"Consultant Big Data orient√© r√©sultats, expert en analyse de donn√©es et optimisation des processus m√©tier.\",\n",
        "        \"D√©veloppeur polyvalent ma√Ætrisant Python, JavaScript et les technologies cloud, avec une forte capacit√© √† r√©soudre des probl√®mes complexes.\"\n",
        "    ]\n",
        "    return random.choice(profiles)\n",
        "\n",
        "# ===============================\n",
        "# SECTION MAPPER\n",
        "# ===============================\n",
        "def make_section_paragraph(label):\n",
        "    if label == \"experience\":\n",
        "        return make_experience_paragraph()\n",
        "    elif label == \"internships\":\n",
        "        return make_internship_paragraph()\n",
        "    elif label == \"projects\":\n",
        "        return make_project_paragraph()\n",
        "    elif label == \"languages\":\n",
        "        return make_languages()\n",
        "    elif label == \"soft_skills\":\n",
        "        return make_soft_skills()\n",
        "    elif label == \"certifications\":\n",
        "        return make_certification()\n",
        "    elif label == \"profile\":\n",
        "        return make_profile()\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "def make_full_cv():\n",
        "    \"\"\"Generate a full CV with all sections concatenated naturally.\"\"\"\n",
        "    sections = SMALL_LABELS.copy()\n",
        "    random.shuffle(sections)\n",
        "    return \" \".join(make_section_paragraph(label) for label in sections)\n",
        "\n",
        "# ===============================\n",
        "# MAIN SCRIPT\n",
        "# ===============================\n",
        "def main():\n",
        "    nlp = spacy.blank(\"fr\")\n",
        "    print(\"üîπ Loading dev dataset...\")\n",
        "    doc_bin = DocBin().from_disk(DEV_FILE)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "    print(f\"‚úÖ Loaded {len(docs)} dev examples\")\n",
        "\n",
        "    # Count current examples per label\n",
        "    counts = {}\n",
        "    for d in docs:\n",
        "        for label, v in d.cats.items():\n",
        "            if v == 1.0:\n",
        "                counts[label] = counts.get(label, 0) + 1\n",
        "\n",
        "    max_count = max(counts.values())\n",
        "    print(\"Largest class in dev:\", max_count)\n",
        "\n",
        "    # Generate synthetic full CVs\n",
        "    new_docs = []\n",
        "    for label in SMALL_LABELS:\n",
        "        n_to_generate = max_count - counts.get(label, 0)\n",
        "        for _ in range(n_to_generate):\n",
        "            text = make_full_cv()\n",
        "            doc = nlp.make_doc(text)\n",
        "            doc.cats = {lbl: float(lbl==label) for lbl in counts.keys()}\n",
        "            new_docs.append(doc)\n",
        "        print(f\"‚úÖ Generated {n_to_generate} synthetic full CVs for {label}\")\n",
        "\n",
        "    # Merge and save\n",
        "    all_docs = docs + new_docs\n",
        "    DocBin(docs=all_docs).to_disk(OUTPUT_FILE)\n",
        "    print(f\"üéâ Dev augmentation complete! Total examples: {len(all_docs)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNSBWKnt9MxE",
        "outputId": "0f128482-928e-42f8-8ba0-de05cde1e967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Loading dev dataset...\n",
            "‚úÖ Loaded 1127 dev examples\n",
            "Largest class in dev: 92\n",
            "‚úÖ Generated 0 synthetic full CVs for experience\n",
            "‚úÖ Generated 0 synthetic full CVs for internships\n",
            "‚úÖ Generated 0 synthetic full CVs for projects\n",
            "‚úÖ Generated 0 synthetic full CVs for languages\n",
            "‚úÖ Generated 0 synthetic full CVs for soft_skills\n",
            "‚úÖ Generated 0 synthetic full CVs for certifications\n",
            "‚úÖ Generated 0 synthetic full CVs for profile\n",
            "üéâ Dev augmentation complete! Total examples: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation of train data"
      ],
      "metadata": {
        "id": "glnkbyR15DcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# CONFIG\n",
        "# ===============================\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/train_augmented1.spacy\"\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/spacy_corpus_finale1/train_augmented.spacy\"\n",
        "\n",
        "# Labels to oversample\n",
        "SMALL_LABELS = [\"experience\", \"internships\", \"projects\", \"languages\", \"soft_skills\", \"certifications\", \"profile\"]\n",
        "\n",
        "# ===============================\n",
        "# SECTION GENERATORS\n",
        "# ===============================\n",
        "\n",
        "# Experience generator\n",
        "def make_experience():\n",
        "    companies = [\"Capgemini\", \"Deloitte\", \"Sopra Steria\", \"BNP Paribas\", \"Vermeg\", \"Ooredoo\", \"Microsoft\", \"IBM\"]\n",
        "    roles = [\"D√©veloppeur Full Stack\", \"Data Scientist\", \"Consultant Big Data\", \"Ing√©nieur Cloud\", \"Analyste Cybers√©curit√©\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement et maintenance d‚Äôapplications\",\n",
        "        \"mise en place de pipelines de donn√©es\",\n",
        "        \"d√©ploiement de solutions cloud s√©curis√©es\",\n",
        "        \"optimisation de mod√®les d‚ÄôIA\",\n",
        "        \"gestion d‚Äô√©quipes agiles et reporting\",\n",
        "        \"analyse des besoins clients et r√©daction des sp√©cifications\",\n",
        "        \"conception d‚Äôarchitectures logicielles √©volutives\"\n",
        "    ]\n",
        "    years = [\"2020‚Äì2022\", \"2019‚Äì2021\", \"2021‚Äì2023\", \"2022‚Äì2024\"]\n",
        "    num_tasks = random.randint(2, 4)\n",
        "    responsibilities = \" ; \".join(random.sample(tasks, num_tasks))\n",
        "    return f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(years)}) ‚Äì Responsabilit√©s : {responsibilities}\"\n",
        "\n",
        "def make_experience_paragraph():\n",
        "    n = random.randint(2, 4)\n",
        "    connectors = [\n",
        "        \"Durant ces exp√©riences professionnelles, j'ai travaill√© sur plusieurs projets significatifs :\",\n",
        "        \"Ces missions m'ont permis de d√©velopper des comp√©tences cl√©s dans le domaine :\",\n",
        "        \"Au cours de ces exp√©riences, j'ai acquis de solides connaissances en :\"\n",
        "    ]\n",
        "    base_text = \" \".join(make_experience() for _ in range(n))\n",
        "    return f\"{random.choice(connectors)} {base_text}\"\n",
        "\n",
        "# Long internship paragraph generator\n",
        "def make_internship_paragraph():\n",
        "    companies = [\"Orange\", \"Eni\", \"STMicroelectronics\", \"Sagemcom\", \"SNCFT\", \"Tunisie T√©l√©com\"]\n",
        "    roles = [\"Stagiaire D√©veloppement Web\", \"Stagiaire Data Analyst\", \"Stagiaire DevOps\", \"Stagiaire S√©curit√© Informatique\"]\n",
        "    tasks = [\n",
        "        \"d√©veloppement d‚Äôun module interne\",\n",
        "        \"analyse de donn√©es clients\",\n",
        "        \"mise en place d‚Äôun pipeline CI/CD\",\n",
        "        \"r√©daction de documentation technique\",\n",
        "        \"tests et validation des fonctionnalit√©s\",\n",
        "        \"participation √† des r√©unions de planification et d'√©valuation\"\n",
        "    ]\n",
        "    periods = [\"Juin‚ÄìAo√ªt 2023\", \"Janvier‚ÄìJuin 2022\", \"F√©vrier‚ÄìAvril 2021\", \"Mars‚ÄìAo√ªt 2020\"]\n",
        "\n",
        "    n = random.randint(3, 5)  # number of internships in the paragraph\n",
        "    sentences = []\n",
        "    for _ in range(n):\n",
        "        sentences.append(f\"{random.choice(roles)} chez {random.choice(companies)} ({random.choice(periods)}), o√π j'ai effectu√© {random.choice(tasks)}.\")\n",
        "    connector = \"Au cours de mes stages, j'ai r√©alis√© plusieurs missions importantes :\"\n",
        "    return f\"{connector} {' '.join(sentences)}\"\n",
        "\n",
        "# Long project paragraph generator\n",
        "def make_project_paragraph():\n",
        "    projects = [\n",
        "        \"un projet universitaire de cr√©ation d‚Äôune application e-commerce en Django\",\n",
        "        \"un projet acad√©mique de d√©veloppement d‚Äôun chatbot NLP avec Python\",\n",
        "        \"un projet personnel de site web de gestion de t√¢ches avec React et Node.js\",\n",
        "        \"un projet de fin d‚Äô√©tudes : plateforme de recommandation musicale avec IA\",\n",
        "        \"une contribution open-source √† une librairie Python de machine learning\",\n",
        "        \"un projet scientifique d‚Äôanalyse pr√©dictive des ventes avec Scikit-learn\"\n",
        "    ]\n",
        "    n = random.randint(3, 5)\n",
        "    sentences = [f\"J'ai men√© {random.choice(projects)}.\" for _ in range(n)]\n",
        "    connector = \"Parmi les projets que j'ai r√©alis√©s, on peut citer :\"\n",
        "    return f\"{connector} {' '.join(sentences)}\"\n",
        "\n",
        "# Languages\n",
        "def make_languages():\n",
        "    langs = [\n",
        "        \"Fran√ßais (courant), Anglais (avanc√©), Arabe (natif)\",\n",
        "        \"Anglais (TOEFL 95), Allemand (interm√©diaire)\",\n",
        "        \"Italien (d√©butant), Fran√ßais (C2), Anglais (C1)\",\n",
        "        \"Espagnol (B2), Arabe (langue maternelle)\"\n",
        "    ]\n",
        "    return random.choice(langs)\n",
        "\n",
        "# Soft skills\n",
        "def make_soft_skills():\n",
        "    skills = [\n",
        "        \"Esprit d‚Äô√©quipe et sens de la communication\",\n",
        "        \"Leadership et capacit√© de prise de d√©cision\",\n",
        "        \"R√©solution de probl√®mes complexes\",\n",
        "        \"Gestion du temps et organisation\",\n",
        "        \"Cr√©ativit√© et pens√©e critique\"\n",
        "    ]\n",
        "    return random.choice(skills)\n",
        "\n",
        "# Certifications\n",
        "def make_certification():\n",
        "    certs = [\n",
        "        \"Certification AWS Solutions Architect ‚Äì Associate\",\n",
        "        \"Certification Cisco CCNA Routing & Switching\",\n",
        "        \"Certification PMP ‚Äì Project Management Professional\",\n",
        "        \"Certification Microsoft Azure Fundamentals\",\n",
        "        \"Certification Scrum Master (PSM I)\"\n",
        "    ]\n",
        "    return random.choice(certs)\n",
        "\n",
        "# Profile\n",
        "def make_profile():\n",
        "    profiles = [\n",
        "        \"Ing√©nieur logiciel passionn√© avec 3 ans d'exp√©rience en d√©veloppement full stack et en gestion de projets agiles.\",\n",
        "        \"Data Scientist sp√©cialis√© en machine learning et intelligence artificielle, avec un solide parcours acad√©mique et professionnel.\",\n",
        "        \"√âtudiant en informatique motiv√© par le d√©veloppement web et la cr√©ation d'applications innovantes.\",\n",
        "        \"Consultant Big Data orient√© r√©sultats, expert en analyse de donn√©es et optimisation des processus m√©tier.\",\n",
        "        \"D√©veloppeur polyvalent ma√Ætrisant Python, JavaScript et les technologies cloud, avec une forte capacit√© √† r√©soudre des probl√®mes complexes.\"\n",
        "    ]\n",
        "    return random.choice(profiles)\n",
        "\n",
        "# ===============================\n",
        "# SECTION MAPPER\n",
        "# ===============================\n",
        "def make_section_paragraph(label):\n",
        "    if label == \"experience\":\n",
        "        return make_experience_paragraph()\n",
        "    elif label == \"internships\":\n",
        "        return make_internship_paragraph()\n",
        "    elif label == \"projects\":\n",
        "        return make_project_paragraph()\n",
        "    elif label == \"languages\":\n",
        "        return make_languages()\n",
        "    elif label == \"soft_skills\":\n",
        "        return make_soft_skills()\n",
        "    elif label == \"certifications\":\n",
        "        return make_certification()\n",
        "    elif label == \"profile\":\n",
        "        return make_profile()\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "def make_full_cv():\n",
        "    \"\"\"Generate a full CV with all sections concatenated naturally.\"\"\"\n",
        "    sections = SMALL_LABELS.copy()\n",
        "    random.shuffle(sections)\n",
        "    return \" \".join(make_section_paragraph(label) for label in sections)\n",
        "\n",
        "# ===============================\n",
        "# MAIN SCRIPT\n",
        "# ===============================\n",
        "def main():\n",
        "    nlp = spacy.blank(\"fr\")\n",
        "    print(\"üîπ Loading train dataset...\")\n",
        "    doc_bin = DocBin().from_disk(TRAIN_FILE)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "    print(f\"‚úÖ Loaded {len(docs)} train examples\")\n",
        "\n",
        "    # Count current examples per label\n",
        "    counts = {}\n",
        "    for d in docs:\n",
        "        for label, v in d.cats.items():\n",
        "            if v == 1.0:\n",
        "                counts[label] = counts.get(label, 0) + 1\n",
        "\n",
        "    max_count = max(counts.values())\n",
        "    print(\"Largest class in train:\", max_count)\n",
        "\n",
        "    # Generate synthetic full CVs\n",
        "    new_docs = []\n",
        "    for label in SMALL_LABELS:\n",
        "        n_to_generate = max_count - counts.get(label, 0)\n",
        "        for _ in range(n_to_generate):\n",
        "            text = make_full_cv()\n",
        "            doc = nlp.make_doc(text)\n",
        "            doc.cats = {lbl: float(lbl==label) for lbl in counts.keys()}\n",
        "            new_docs.append(doc)\n",
        "        print(f\"‚úÖ Generated {n_to_generate} synthetic full CVs for {label}\")\n",
        "\n",
        "    # Merge and save\n",
        "    all_docs = docs + new_docs\n",
        "    DocBin(docs=all_docs).to_disk(OUTPUT_FILE)\n",
        "    print(f\"üéâ Train augmentation complete! Total examples: {len(all_docs)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtkkBo6p9VZ7",
        "outputId": "3f599ed7-30ae-4a01-cac5-7316ff4dfbe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Loading train dataset...\n",
            "‚úÖ Loaded 4720 train examples\n",
            "Largest class in train: 426\n",
            "‚úÖ Generated 0 synthetic full CVs for experience\n",
            "‚úÖ Generated 64 synthetic full CVs for internships\n",
            "‚úÖ Generated 56 synthetic full CVs for projects\n",
            "‚úÖ Generated 2 synthetic full CVs for languages\n",
            "‚úÖ Generated 27 synthetic full CVs for soft_skills\n",
            "‚úÖ Generated 1 synthetic full CVs for certifications\n",
            "‚úÖ Generated 0 synthetic full CVs for profile\n",
            "üéâ Train augmentation complete! Total examples: 4870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating second model after data augmentation"
      ],
      "metadata": {
        "id": "PMVfAzII40vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config ./config.cfg --lang fr --pipeline textcat --optimize accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng9CVO99-3uY",
        "outputId": "962e060b-ab24-4c65-d732-93f9cb1060a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m‚ö† To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Generated config template specific for your use case\u001b[0m\n",
            "- Language: fr\n",
            "- Pipeline: textcat\n",
            "- Optimize for: accuracy\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m‚úî Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m‚úî Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train --output /content/drive/MyDrive/spacy_corpus_finale1/output_model \\\n",
        "    /content/config.cfg \\\n",
        "    --paths.train /content/drive/MyDrive/spacy_corpus_finale1/train_augmented1.spacy \\\n",
        "    --paths.dev /content/drive/MyDrive/spacy_corpus_finale1/dev_augmented.spacy \\\n",
        "    --gpu-id -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExbYqU4_-ZoN",
        "outputId": "889cd15e-a73e-4f78-ce90-8fe1e0b07997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m‚úî Created output directory:\n",
            "/content/drive/MyDrive/spacy_corpus_finale1/output_model\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Saving to output directory:\n",
            "/content/drive/MyDrive/spacy_corpus_finale1/output_model\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m‚úî Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Pipeline: ['tok2vec', 'textcat']\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
            "---  ------  ------------  ------------  ----------  ------\n",
            "  0       0          0.00          0.07        7.52    0.08\n",
            "  0     200         69.00          7.67       73.43    0.73\n",
            "  0     400        228.15          6.44       87.09    0.87\n",
            "  0     600        342.48          6.70       85.17    0.85\n",
            "  0     800        823.70          5.29       82.68    0.83\n",
            "  1    1000       1619.14          6.18       93.77    0.94\n",
            "  1    1200       1608.95          6.12       92.58    0.93\n",
            "  1    1400       2470.53          4.00       91.64    0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lhwlie017Hnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of second model"
      ],
      "metadata": {
        "id": "xpdPxYah7IhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/model-best /content/drive/MyDrive/spacy_corpus_finale1/deva.spacy --gpu-id -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFwbNATu6gXg",
        "outputId": "65dcba92-d616-4a1e-d726-694a9d3c7eb9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK                 100.00\n",
            "TEXTCAT (macro F)   93.77 \n",
            "SPEED               2681  \n",
            "\n",
            "\u001b[1m\n",
            "=========================== Textcat F (per label) ===========================\u001b[0m\n",
            "\n",
            "                        P        R       F\n",
            "country             96.51    97.65   97.08\n",
            "phone               98.36   100.00   99.17\n",
            "soft_skills         97.47    83.70   90.06\n",
            "education           96.51    92.22   94.32\n",
            "projects            75.47    86.96   80.81\n",
            "email              100.00    98.84   99.42\n",
            "technical_skills    96.59    92.39   94.44\n",
            "name                92.11   100.00   95.89\n",
            "internships         86.67    71.43   78.31\n",
            "languages           97.85    98.91   98.38\n",
            "experience          96.84   100.00   98.40\n",
            "certifications      88.35    98.91   93.33\n",
            "profile             98.92   100.00   99.46\n",
            "\n",
            "\u001b[1m\n",
            "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
            "\n",
            "                   ROC AUC\n",
            "country               0.99\n",
            "phone                 1.00\n",
            "soft_skills           0.98\n",
            "education             0.99\n",
            "projects              0.99\n",
            "email                 1.00\n",
            "technical_skills      0.99\n",
            "name                  1.00\n",
            "internships           0.99\n",
            "languages             0.99\n",
            "experience            1.00\n",
            "certifications        1.00\n",
            "profile               1.00\n",
            "\n"
          ]
        }
      ]
    }
  ]
}